{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq Model for Neural Machine Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNlf45MpWpxfpmt9+aL33S6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bala-codes/Natural-Language-Processing-NLP/blob/master/Neural%20Machine%20Translation/1.%20Seq2Seq%20%5BEnc%20%2B%20Dec%5D%20Model%20for%20Neural%20Machine%20Translation%20(Without%20Attention%20Mechanism).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxGjrP6hWeB9",
        "colab_type": "text"
      },
      "source": [
        "# A Comprehensive Guide to Neural Machine Translation using Seq2Seq Modelling using PyTorch\n",
        "\n",
        "## In this post, we will be building a sequence to sequence deep learning model using PyTorch and TorchText. Here I am doing an German to English neural machine translation. But the same concept can be extended to other problems such as Named Entity Recognition (NER), Text Summarization etc,."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rr5xoWgk4Lb",
        "colab_type": "text"
      },
      "source": [
        "# Table of Contents:\n",
        "## 1. Introduction\n",
        "## 2. Data Preparation and Pre-processing\n",
        "## 3. Long Short Term Memory (LSTM) - Under the Hood\n",
        "## 4. Encoder Model Architecture (Seq2Seq)¶\n",
        "## 5. Encoder Code Implementation (Seq2Seq)\n",
        "## 6. Decoder Model Architecture (Seq2Seq)\n",
        "## 7. Decoder Code Implementation (Seq2Seq)\n",
        "## 8. Seq2Seq (Encoder + Decoder) Interface\n",
        "## 9. Seq2Seq (Encoder + Decoder) Code Implementation\n",
        "## 10. Seq2Seq Model Training\n",
        "## 11. Seq2Seq Model Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pSOAqoHlD3y",
        "colab_type": "text"
      },
      "source": [
        "# 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2fGJ_1qXRxu",
        "colab_type": "text"
      },
      "source": [
        "Here I am doing a German to English neural machine translation. But the same concept can be extended to other problems such as Named Entity Recognition (NER), Text Summarization, etc,.\n",
        "\n",
        "So the Sequence to Sequence (seq2seq) model in this post uses an encoder-decoder architecture, which uses a type of RNN called LSTM (Long Short Term Memory), where the encoder neural network encodes the input german sequence into a single vector, also called as a Context Vector.\n",
        "This Context Vector is said to contain the abstract representation of the input german sequence.\n",
        "\n",
        "This vector is then passed into the decoder neural network, which is used to output the corresponding English translation sentence, one word at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSuJ-9X_qk1b",
        "colab_type": "text"
      },
      "source": [
        "# Necessary Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Ycz13hbUbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a7de9cd3-87c1-44fe-a086-8e561932435c"
      },
      "source": [
        "!pip install torchtext==0.6.0 --quiet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import random\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from pprint import pprint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "'''\n",
        "# Seeding for reproducible results everytime\n",
        "SEED = 777\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Seeding for reproducible results everytime\\nSEED = 777\\n\\nrandom.seed(SEED)\\nnp.random.seed(SEED)\\ntorch.manual_seed(SEED)\\ntorch.cuda.manual_seed(SEED)\\ntorch.backends.cudnn.deterministic = True'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42fLcaN_kPxf",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data Preparation & Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FHjZ6RnqoNJ",
        "colab_type": "text"
      },
      "source": [
        "Loading the SpaCy's vocabulary for our desired languages. SpaCy also supports many languages like french, german etc,.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrNraUABrDq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5961207b-7121-488f-af92-e17b9ac73c1f"
      },
      "source": [
        "!python -m spacy download en --quiet\n",
        "!python -m spacy download de --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 531kB/s \n",
            "\u001b[?25h  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Da1d8Pb-p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_german = spacy.load(\"de\")\n",
        "spacy_english = spacy.load(\"en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu2SLNiZrd0Q",
        "colab_type": "text"
      },
      "source": [
        "Now let's create custom tokenization methods for the languages. Tokenization is a process of breaking the sentence into a list of individual tokens (words).\n",
        "\n",
        "We can make use of PyTorch's TorchText library for data pre-processing and SpaCy for vocabulary building (English and German) & tokenization of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leVROD_6qz16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "940587fb-fa3c-4b0d-a7b9-cf5003d6709a"
      },
      "source": [
        "def tokenize_german(text):\n",
        "  return [token.text for token in spacy_german.tokenizer(text)]\n",
        "\n",
        "def tokenize_english(text):\n",
        "  return [token.text for token in spacy_english.tokenizer(text)]\n",
        "\n",
        "### Sample Run ###\n",
        "\n",
        "sample_text = \"I love machine learning\"\n",
        "print(tokenize_english(sample_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'love', 'machine', 'learning']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfbseIvPUuFz",
        "colab_type": "text"
      },
      "source": [
        "Torch text is a powerful library for making the text data ready for variety of NLP tasks. It has all the tools to perform preprocessing on the textual data.\n",
        "\n",
        "Let's see some of the process it can do,\n",
        "\n",
        "1. Train/ Valid/ Test Split: partition your data into a specified train/ valid/ test set.\n",
        "\n",
        "2. File Loading: load the text corpus of various formats (.txt,.json,.csv).\n",
        "3. Tokenization: breaking sentences into list of words.\n",
        "4. Vocab: Generate a list of vocabulary from the text corpus.\n",
        "5. Words to Integer Mapper: Map words into integer numbers for the entire corpus and vice versa.\n",
        "6. Word Vector: Convert a word from higher dimension to lower dimension (Word Embedding).\n",
        "7. Batching: Generate batches of sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRa1BNkOU3nK",
        "colab_type": "text"
      },
      "source": [
        "So once we get to understand what can be done in torch text, let's talk about how it can be implemented in the torch text module. Here we are going to make use of 3 classes under torch text.\n",
        "\n",
        "1. Fields :\n",
        "> This is a class under the torch text, where we specify how the preprocessing should be done on our data corpus.\n",
        "2. TabularDataset : \n",
        "> Using this class, we can actually define the Dataset of columns stored in CSV, TSV, or JSON format and also map them into integers.\n",
        "3. BucketIterator :\n",
        "> Using this class, we can perform padding our data for approximation and make batches with our data for model training.\n",
        "\n",
        "Here our source language (SRC - Input) is German and target language (TRG - Output) is English. We also add 2 extra tokens \"start of sequence\" <sos> and \"end of sequence\" <EOS> for effective model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn8CDZ1ssIju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "89a750dc-cffe-4316-ba57-155f67ed7675"
      },
      "source": [
        "german = Field(tokenize=tokenize_german,\n",
        "               lower=True,\n",
        "               init_token=\"<sos>\",\n",
        "               eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(tokenize=tokenize_english,\n",
        "               lower=True,\n",
        "               init_token=\"<sos>\",\n",
        "               eos_token=\"<eos>\")\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = (\".de\", \".en\"),\n",
        "                                                    fields=(german, english))\n",
        "\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=3)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 671kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 175kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 167kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILXUMSRVLhb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e55efed2-501e-4f25-fdb1-5a1fe816f739"
      },
      "source": [
        "print(f\"Unique tokens in source (de) vocabulary: {len(german.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (de) vocabulary: 5376\n",
            "Unique tokens in target (en) vocabulary: 4556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiRsZjvEME18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73256f46-cc6d-4526-f0a0-1e34008a5be0"
      },
      "source": [
        "# dir(english.vocab)\n",
        "\n",
        "print(english.vocab.__dict__.keys())\n",
        "print(list(english.vocab.__dict__.values()))\n",
        "e = list(english.vocab.__dict__.values())\n",
        "for i in e:\n",
        "  print(i)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprint(english.vocab.__dict__.keys())\\nprint(list(english.vocab.__dict__.values()))\\ne = list(english.vocab.__dict__.values())\\nfor i in e:\\n  print(i)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhhJy36TM4SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_2_idx = dict(e[3])\n",
        "idx_2_word = {}\n",
        "for k,v in word_2_idx.items():\n",
        "  idx_2_word[v] = k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb-ecGHHxQCS",
        "colab_type": "text"
      },
      "source": [
        "# Dataset sneek peek"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvt8AUrWvbA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e9c3c5bb-6960-4e51-c1de-3a0ea96bb6a4"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
        "\n",
        "print(train_data[5].__dict__.keys())\n",
        "pprint(train_data[5].__dict__.values())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n",
            "dict_keys(['src', 'trg'])\n",
            "dict_values([['ein', 'mann', 'in', 'grün', 'hält', 'eine', 'gitarre', ',', 'während', 'der', 'andere', 'mann', 'sein', 'hemd', 'ansieht', '.'], ['a', 'man', 'in', 'green', 'holds', 'a', 'guitar', 'while', 'the', 'other', 'man', 'observes', 'his', 'shirt', '.']])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5CbOTA-nCMF",
        "colab_type": "text"
      },
      "source": [
        "After setting the language pre-processing criteria, the next step is to create batches of training, testing and validation data using iterators.\n",
        "\n",
        "Creating batches is an exhaustive process, luckily we can make use of TorchText's iterator libraries.\n",
        "\n",
        "Here we are using BucketIterator for effective padding of source and target sentences. We can access the source (german) batch of data using .src attribute and it's correspondign (english) batch of data using .trg attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gmz5adIwbwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n",
        "                                                                      batch_size = BATCH_SIZE, \n",
        "                                                                      sort_within_batch=True,\n",
        "                                                                      sort_key=lambda x: len(x.src),\n",
        "                                                                      device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvYIL8X1-LAP",
        "colab_type": "text"
      },
      "source": [
        "## Actual text data before tokenized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vWNHTlL8nSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "c50535ec-de6b-4a9f-9815-3d810ed9899b"
      },
      "source": [
        "count = 0\n",
        "max_len_eng = []\n",
        "max_len_ger = []\n",
        "for data in train_data:\n",
        "  max_len_ger.append(len(data.src))\n",
        "  max_len_eng.append(len(data.trg))\n",
        "  if count < 10 :\n",
        "    print(\"German - \",*data.src, \" Length - \", len(data.src))\n",
        "    print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n",
        "    print()\n",
        "  count += 1\n",
        "\n",
        "print(\"Maximum Length of English sentence {} and German sentence {} in the dataset\".format(max(max_len_eng),max(max_len_ger)))\n",
        "print(\"Minimum Length of English sentence {} and German sentence {} in the dataset\".format(min(max_len_eng),min(max_len_ger)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "German -  zwei junge weiße männer sind im freien in der nähe vieler büsche .  Length -  13\n",
            "English -  two young , white males are outside near many bushes .  Length -  11\n",
            "\n",
            "German -  mehrere männer mit schutzhelmen bedienen ein antriebsradsystem .  Length -  8\n",
            "English -  several men in hard hats are operating a giant pulley system .  Length -  12\n",
            "\n",
            "German -  ein kleines mädchen klettert in ein spielhaus aus holz .  Length -  10\n",
            "English -  a little girl climbing into a wooden playhouse .  Length -  9\n",
            "\n",
            "German -  ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster .  Length -  15\n",
            "English -  a man in a blue shirt is standing on a ladder cleaning a window .  Length -  15\n",
            "\n",
            "German -  zwei männer stehen am herd und bereiten essen zu .  Length -  10\n",
            "English -  two men are at the stove preparing food .  Length -  9\n",
            "\n",
            "German -  ein mann in grün hält eine gitarre , während der andere mann sein hemd ansieht .  Length -  16\n",
            "English -  a man in green holds a guitar while the other man observes his shirt .  Length -  15\n",
            "\n",
            "German -  ein mann lächelt einen ausgestopften löwen an .  Length -  8\n",
            "English -  a man is smiling at a stuffed lion  Length -  8\n",
            "\n",
            "German -  ein schickes mädchen spricht mit dem handy während sie langsam die straße entlangschwebt .  Length -  14\n",
            "English -  a trendy girl talking on her cellphone while gliding slowly down the street .  Length -  14\n",
            "\n",
            "German -  eine frau mit einer großen geldbörse geht an einem tor vorbei .  Length -  12\n",
            "English -  a woman with a large purse is walking by a gate .  Length -  12\n",
            "\n",
            "German -  jungen tanzen mitten in der nacht auf pfosten .  Length -  9\n",
            "English -  boys dancing on poles in the middle of the night .  Length -  11\n",
            "\n",
            "Maximum Length of English sentence 41 and German sentence 44 in the dataset\n",
            "Minimum Length of English sentence 4 and German sentence 1 in the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYL8BmZI0Bzh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e4665c5-de0f-43c9-fb8d-ccccad7a1f7e"
      },
      "source": [
        "count = 0\n",
        "for data in train_iterator:\n",
        "  if count < 1 :\n",
        "    print(\"Shapes\", data.src.shape, data.trg.shape)\n",
        "    print()\n",
        "    print(\"German - \",*data.src, \" Length - \", len(data.src))\n",
        "    print()\n",
        "    print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n",
        "    temp_ger = data.src\n",
        "    temp_eng = data.trg\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes torch.Size([23, 32]) torch.Size([32, 32])\n",
            "\n",
            "German -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([  5,   5,   5,   8,   8,   5,   5,   8,   5,   5, 105,  15,   8,   8,\n",
            "          8,   5,   5,  18,   5,   5,   5, 105,  18,   5,   8,   5,   5,   5,\n",
            "         18,   5,   8,   5], device='cuda:0') tensor([   0, 1380, 3448,  165,  330,   13,   26,   16,   70,   13,   30, 2239,\n",
            "         230,   36,   16, 1227,   96,   65,   13,    0,   13,   54,   30,   13,\n",
            "          16,   13,    7,   70,   30,   49,  926,   96], device='cuda:0') tensor([ 572,  533, 1575,    7,   16,   11,    7,   11,   26,    7,    9,   11,\n",
            "           9,   22,    7,   29,   13,   57,   10,    9,    7,   17,  185,    7,\n",
            "           7,  412, 1032,   26,  179,    9,  327,   13], device='cuda:0') tensor([  11,   11,   49,  234,   10,   14, 2485,   14,   11,  219,   18,   15,\n",
            "          17,   41,    6,   12,    0,   55,    5,   15,    6,  232,   23,    6,\n",
            "           6,  429,  229,   11,    7,   39,    8,    7], device='cuda:0') tensor([  77,    6,  146,   95,    5,    0,   68,   71, 1127,   10,    7,  474,\n",
            "          56,   29,   50,  426,    8,   91,   32,   19,   82,  358,  131,   46,\n",
            "          71,    7,   26,    6,   14,   19,  798,  226], device='cuda:0') tensor([  49, 4052,   58,   23, 1736,   89,    8,   89,  260,    0,   51,  640,\n",
            "         628,  133,   79,  214,    0,    4,   12,   78,  120,   84,   11,   40,\n",
            "          79,   14,   68,  257,  309,    0,  870,  120], device='cuda:0') tensor([  10,   10,    5,   17,   49,   60, 4017,   10,   10,  287,  486,    0,\n",
            "         242,    9,   10,   55,  119,   39,   14,    9,   61,    9,   14,   38,\n",
            "          10,   46,  448,   40,   10,   61,    7,   10], device='cuda:0') tensor([   6,    6,  379,  599,   74,   11, 1869,   14,   46,   23,    9,   29,\n",
            "        1794,   10,   11,  235,    9,   49,  813, 3655,   19,   84,   16,    5,\n",
            "           6, 4753,   22,   60,  400,    9,    6,  160], device='cuda:0') tensor([  32,  250,   12, 2846,   21,  584,  254,   71,  454,   42,   14,   12,\n",
            "           9,    7,   14,   10,   35,    7,   20,    9,  634,   12,    9, 1403,\n",
            "          82,   10,   77,   28, 2372,   31,  239,    9], device='cuda:0') tensor([  31, 1806,   39,   21,   14,    7,  235, 1391,   29,   39,    7,   77,\n",
            "          29,   15,  199,  108,    5,  199,  670,  977,   12,    6,  231,   12,\n",
            "         451,   11, 1133,  361,   27,   12,   10,   15], device='cuda:0') tensor([  20, 1546,   63,    9, 1215,   15,    9,   60,  590,  379,  237,  273,\n",
            "          12,  436,  391,   22,   25, 1150,    9,  106,   77,  112,   84,  197,\n",
            "         297,    6,   20,   58,    9,   24,   31,   19], device='cuda:0') tensor([  88,    0,    9, 1832,   72,   81,   98,   12,   14,   44,  263,   10,\n",
            "          15, 1000,   61,   15,  434,  222,   35,   61,  143,  194,  768,  129,\n",
            "          10,  410,  257,   39,   17,  122,  147, 1240], device='cuda:0') tensor([   7,   21,   35,   99,   10, 1084,  176,   24,    0,    0,   10,   48,\n",
            "         136,    8,   19,  465,    9,   10,    7,    9,    9,   11,   64,    9,\n",
            "         108,  106,  571,  118,    7,   47,   47,   85], device='cuda:0') tensor([   6,    6,    7,   58,  187,    9,   84,  142, 2719,    9,   15,   20,\n",
            "           9,   16,   46,    0,    0,   39,   15,   31,   35,   94,   99,   35,\n",
            "         147,   29,    9,    7,    6,    6,    6,    5], device='cuda:0') tensor([   0, 2245, 2283,   17,   19,   35,   58,   10,    9,   11, 1594, 2494,\n",
            "         169,  125, 1165,    9,    9,   49,  481,   12,  145, 1692,  140,    8,\n",
            "          22,   11,   15,   15, 1997,   13, 4129, 2625], device='cuda:0') tensor([  10,    0, 1937,    0,  417,   18,   33,   95,   10, 1737,   20,    9,\n",
            "          10,   81,  266,   17,  588,    7,  221,    6,   11,   10,   10,   16,\n",
            "           6, 2443,   12,  110,   98,    9,  251,   61], device='cuda:0') tensor([ 182,   10,  221,  115,    9, 1067, 1737,  147,   20,   10,   86,  149,\n",
            "        1635,  193, 1097, 1644,   10,  518,   41, 1717,   14, 2132,    5,   10,\n",
            "          13,  442,   77,   22,  205,   15,  332,    9], device='cuda:0') tensor([ 149,   12,   55,   20,   35,    5,  841,   12,   86,  629,    9, 1567,\n",
            "           7,  207,   12,   55,    0,   29,   28,   47,   36, 1550,  104,    5,\n",
            "          20,   27,  186,    5,    0,    8,    7,  539], device='cuda:0') tensor([ 624,   15,   91,  155,  231,  209,   28,  134,   52,   20,   57,  994,\n",
            "          17,   44,   24, 2333,   20,   20,  144,  197,   73,   20,   20,   49,\n",
            "          86,    6, 1431,  116,  264,    0,   14,    8], device='cuda:0') tensor([  21, 5184,   57,  146, 2653,  167,  144, 2674,    0,   86,  215, 3603,\n",
            "         363,  395,  143,   29,   86,   63,   84, 5288,  750,   86,   86, 3545,\n",
            "         290,    0,   68,  294, 4094,   37,    0,   34], device='cuda:0') tensor([4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0') tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')  Length -  23\n",
            "\n",
            "English -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([  4,   4,   4,   4,  21,   4,   4,   4,   4,   4, 110,   7,   4,   4,\n",
            "          4,   4,   4,  16,   4,   4,   4, 110,  16,   4,   4,   4,   7,   4,\n",
            "         16,  55,  21,   4], device='cuda:0') tensor([4314,  178, 1585,  120,  387,  174,   34,   14,   24,    9,   30,  939,\n",
            "         200,   38,   14, 1421,   24,   63,    9,  523,    9,   19,   30,    9,\n",
            "          14,  168,   34,   53,   30,   22,  106,   24], device='cuda:0') tensor([ 665,   42,   55,    6,   14,  125,    6,   13,   34,    6,   17,    8,\n",
            "          12,   12,    6,   10,    9,   37,   11,   15,    6,   22,   17,    6,\n",
            "          73,   42,    6,   34,   17, 1553,   33,    9], device='cuda:0') tensor([  13,  210,   91,   29,   11,   13,  731,    4,   13,  148,   37,    7,\n",
            "         115,   19,    4,   36, 1708,   20,    4,   22,    4,   25,  633,    7,\n",
            "           6,  433,  132,   13,  130,  102,   10,    6], device='cuda:0') tensor([  27,  524,   56,   15,    4,  371,  846,   26,  122,   11,  123, 1057,\n",
            "          30,   17,   31,    8,   51,    4,   35,    4,   52,   17, 2395,   29,\n",
            "           4,    9,   10,    4,    6,   67,  351,    4], device='cuda:0') tensor([ 55,  13,  60, 165,  24,   6, 380,  81,  42,   4,  15,  15,   8, 359,\n",
            "         23,  74,   4,  88,   8,  59,  23,   8,   4,  23,  26,  22, 165, 194,\n",
            "          4,  91,   4,  26], device='cuda:0') tensor([  11,    4,    4,    4,  161,   27,    4,   11,   97, 2314,   16,  448,\n",
            "         149,  129,   11,  392,    0,   15,    4,   42,   10,    4,   14,   10,\n",
            "         109,    4,  426,   23,  284,    8,  518,   23], device='cuda:0') tensor([  35, 1283,  598,  700,   55,  139,    0,   26,   11,   23,    6,    0,\n",
            "         133,   11,  204,   49,  922,   46,  118, 3311,  151,   70,   57,   37,\n",
            "          11,   29,   12,   41,  370,  185,   12,   11], device='cuda:0') tensor([  10,   11,   20,  214,   41,   11,   69,  645,   29,  716,   25,   15,\n",
            "          11,    6,   67,    7,  630,    6,  144,  282,    4,  180,   15,    4,\n",
            "          52, 1161,   27,   60,    0,   71,  517,  175], device='cuda:0') tensor([  32,   22,    7,   12,  124,    4,    7,   41,  542,   76, 1124,   10,\n",
            "        1769,    7,  504, 1064,   58,   90,    6,   67,  612,   13,  176, 1393,\n",
            "         451,   81,  851,    7,   18,   18,    6,   11], device='cuda:0') tensor([   6,    4,   47,    7,    4,    0,  225,    0,   89,    7,   15, 3580,\n",
            "          66,  168,    4,   15,    4,   15,    7,   15,  320,  285,   17,    8,\n",
            "         239,   11,    6,   96,  247,    9,    4,  151], device='cuda:0') tensor([   4,  317,   28, 3728,  856,   81,   28,    7, 1975,  661,   46,   54,\n",
            "         181,    4,   29, 2511,   24,  775,  725,   10,   27, 1110,  250,   27,\n",
            "          15,    4,    7,   80, 3356,   45,  235,    4], device='cuda:0') tensor([1640,   10,   19,   49,   15,    8,  488,   84,    4,   12,    6,   27,\n",
            "           5,   14, 1366,   49,   33,    6,   15,   32,  172,   11,   83,  126,\n",
            "          58,  384,  194,   74,    6,    4,   32, 1862], device='cuda:0') tensor([243,   0, 128,  56,  45,  58, 509,  28, 276,   4,   4,  71,   3,  10,\n",
            "        298,   7, 107,   7,  13,   8,  28, 322, 155,  28,   4,  67, 437, 250,\n",
            "          7,   0,  71,  54], device='cuda:0') tensor([  57, 4306,    8,    6,   21,   16,   60,   56,  478, 1922,   31, 1515,\n",
            "           1, 3312,   12,  427,    8,  211,    4,    4,  119,   42,   11,    4,\n",
            "           9,   10,  169,    5, 1728,    5,   18,    4], device='cuda:0') tensor([  15,    0,    7,    7,  297,  360,    7,   20,   12,  180,  495,    5,\n",
            "           1,   44,  581,   15,   15,   11,   38, 1140,   18,   40,    4,   14,\n",
            "           6,   36,  901,    3,   93,    3,    4,  770], device='cuda:0') tensor([  11,    8,   88,   36,   15,  389, 2500,   44, 2633,   15,   11,    3,\n",
            "           1,  139,    8,  439,    4,    7,   12,   71,    4, 1497,   77,   11,\n",
            "           7,   13,    8,    1,  155,    1,  573,  487], device='cuda:0') tensor([  56,   21,    6,  116,   28,   27,   93,  286,   28,   13,    4,    1,\n",
            "           1,   18,   44,   10,  457, 1940,   41,   18,   38,   93,    6,    4,\n",
            "          98, 1891,   27,    1,    5,    1,   12,   10], device='cuda:0') tensor([  20,  145,    4,   20,  141,  134,  143,    5,  355, 2500, 1052,    1,\n",
            "           1,    7,  172,   80,   42,   55,   19,   27,   12,  155,    7,   55,\n",
            "         107,  364,  264,    1,    3,    1,   31,  483], device='cuda:0') tensor([  27,   42,  452,  118,  102,    5,    5,    3,  788,   11,    6,    1,\n",
            "           1,  158,    5,    7, 1804,   15,    6, 1841,   19,    5,   98, 1796,\n",
            "           8,   57,    5,    1,    1,    1,  367,    4], device='cuda:0') tensor([ 707, 1887,    5,    5, 2571,    3,    3,    1,  100,  488,    7,    1,\n",
            "           1,   12,    3, 2158,   15,    6,    7,    5,    5,    3,    5,    5,\n",
            "           5,    4,    3,    1,    1,    1,    6,   39], device='cuda:0') tensor([   5,  418,    3,    3,    5,    1,    1,    1,    6,    6,   98,    1,\n",
            "           1,    4,    1,    5, 1220,   52,  452,    3,    3,    1,    3,    3,\n",
            "           3,  101,    1,    1,    1,    1,    4,    5], device='cuda:0') tensor([   3, 2040,    1,    1,    3,    1,    1,    1,    7,    7,    5,    1,\n",
            "           1,    9,    1,    3,   15,   15,    5,    1,    1,    1,    1,    1,\n",
            "           1,   77,    1,    1,    1,    1, 1001,    3], device='cuda:0') tensor([ 1, 11,  1,  1,  1,  1,  1,  1, 98, 98,  3,  1,  1,  5,  1,  1, 11, 36,\n",
            "         3,  1,  1,  1,  1,  1,  1,  5,  1,  1,  1,  1,  5,  1],\n",
            "       device='cuda:0') tensor([   1,    7,    1,    1,    1,    1,    1,    1,    5,    5,    1,    1,\n",
            "           1,    3,    1,    1, 1476,    6,    1,    1,    1,    1,    1,    1,\n",
            "           1,    3,    1,    1,    1,    1,    3,    1], device='cuda:0') tensor([   1, 1088,    1,    1,    1,    1,    1,    1,    3,    3,    1,    1,\n",
            "           1,    1,    1,    1, 3110,    7,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1], device='cuda:0') tensor([ 1,  5,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  6, 47,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "       device='cuda:0') tensor([1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 5, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0') tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 98,  3,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "       device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')  Length -  32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr7ue9mDRNLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_eng_idx = (temp_eng).cpu().detach().numpy()\n",
        "temp_ger_idx = (temp_ger).cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27RquKagotom",
        "colab_type": "text"
      },
      "source": [
        "I just experimented with a batch size of 32 and a sample target batch is shown below. The sentences are tokenized into list of words and indexed according to the vocabulary. The \"pad\" token gets an index of 1.\n",
        "\n",
        "Each column corresponds to a sentence indexed into numbers and we have 32 such sentences in a single target batch and the number of rows corresponds to the maximum length of that sentence. Short sentences are padded with 1 to compensate.\n",
        "The table (Idx.csv) contains the numerical indices of the words, which is later fed into the word embedding and converted into dense representation for Seq2Seq processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dg028v3Ru7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e92672e6-4f1b-420b-f971-bd5dda9ce405"
      },
      "source": [
        "df_eng_idx = pd.DataFrame(data = temp_eng_idx, columns = [str(\"S_\")+str(x) for x in np.arange(1, 33)])\n",
        "df_eng_idx.index.name = 'Time Steps'\n",
        "df_eng_idx.index = df_eng_idx.index + 1 \n",
        "# df_eng_idx.to_csv('/content/idx.csv')\n",
        "df_eng_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S_1</th>\n",
              "      <th>S_2</th>\n",
              "      <th>S_3</th>\n",
              "      <th>S_4</th>\n",
              "      <th>S_5</th>\n",
              "      <th>S_6</th>\n",
              "      <th>S_7</th>\n",
              "      <th>S_8</th>\n",
              "      <th>S_9</th>\n",
              "      <th>S_10</th>\n",
              "      <th>S_11</th>\n",
              "      <th>S_12</th>\n",
              "      <th>S_13</th>\n",
              "      <th>S_14</th>\n",
              "      <th>S_15</th>\n",
              "      <th>S_16</th>\n",
              "      <th>S_17</th>\n",
              "      <th>S_18</th>\n",
              "      <th>S_19</th>\n",
              "      <th>S_20</th>\n",
              "      <th>S_21</th>\n",
              "      <th>S_22</th>\n",
              "      <th>S_23</th>\n",
              "      <th>S_24</th>\n",
              "      <th>S_25</th>\n",
              "      <th>S_26</th>\n",
              "      <th>S_27</th>\n",
              "      <th>S_28</th>\n",
              "      <th>S_29</th>\n",
              "      <th>S_30</th>\n",
              "      <th>S_31</th>\n",
              "      <th>S_32</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time Steps</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>110</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>110</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>55</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4314</td>\n",
              "      <td>178</td>\n",
              "      <td>1585</td>\n",
              "      <td>120</td>\n",
              "      <td>387</td>\n",
              "      <td>174</td>\n",
              "      <td>34</td>\n",
              "      <td>14</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>939</td>\n",
              "      <td>200</td>\n",
              "      <td>38</td>\n",
              "      <td>14</td>\n",
              "      <td>1421</td>\n",
              "      <td>24</td>\n",
              "      <td>63</td>\n",
              "      <td>9</td>\n",
              "      <td>523</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>168</td>\n",
              "      <td>34</td>\n",
              "      <td>53</td>\n",
              "      <td>30</td>\n",
              "      <td>22</td>\n",
              "      <td>106</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>665</td>\n",
              "      <td>42</td>\n",
              "      <td>55</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>125</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>37</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>73</td>\n",
              "      <td>42</td>\n",
              "      <td>6</td>\n",
              "      <td>34</td>\n",
              "      <td>17</td>\n",
              "      <td>1553</td>\n",
              "      <td>33</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13</td>\n",
              "      <td>210</td>\n",
              "      <td>91</td>\n",
              "      <td>29</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>731</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>148</td>\n",
              "      <td>37</td>\n",
              "      <td>7</td>\n",
              "      <td>115</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>1708</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>633</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>433</td>\n",
              "      <td>132</td>\n",
              "      <td>13</td>\n",
              "      <td>130</td>\n",
              "      <td>102</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27</td>\n",
              "      <td>524</td>\n",
              "      <td>56</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>371</td>\n",
              "      <td>846</td>\n",
              "      <td>26</td>\n",
              "      <td>122</td>\n",
              "      <td>11</td>\n",
              "      <td>123</td>\n",
              "      <td>1057</td>\n",
              "      <td>30</td>\n",
              "      <td>17</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>51</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>52</td>\n",
              "      <td>17</td>\n",
              "      <td>2395</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>67</td>\n",
              "      <td>351</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>55</td>\n",
              "      <td>13</td>\n",
              "      <td>60</td>\n",
              "      <td>165</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>380</td>\n",
              "      <td>81</td>\n",
              "      <td>42</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>359</td>\n",
              "      <td>23</td>\n",
              "      <td>74</td>\n",
              "      <td>4</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>59</td>\n",
              "      <td>23</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>22</td>\n",
              "      <td>165</td>\n",
              "      <td>194</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>161</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>97</td>\n",
              "      <td>2314</td>\n",
              "      <td>16</td>\n",
              "      <td>448</td>\n",
              "      <td>149</td>\n",
              "      <td>129</td>\n",
              "      <td>11</td>\n",
              "      <td>392</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>109</td>\n",
              "      <td>4</td>\n",
              "      <td>426</td>\n",
              "      <td>23</td>\n",
              "      <td>284</td>\n",
              "      <td>8</td>\n",
              "      <td>518</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>35</td>\n",
              "      <td>1283</td>\n",
              "      <td>598</td>\n",
              "      <td>700</td>\n",
              "      <td>55</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>11</td>\n",
              "      <td>204</td>\n",
              "      <td>49</td>\n",
              "      <td>922</td>\n",
              "      <td>46</td>\n",
              "      <td>118</td>\n",
              "      <td>3311</td>\n",
              "      <td>151</td>\n",
              "      <td>70</td>\n",
              "      <td>57</td>\n",
              "      <td>37</td>\n",
              "      <td>11</td>\n",
              "      <td>29</td>\n",
              "      <td>12</td>\n",
              "      <td>41</td>\n",
              "      <td>370</td>\n",
              "      <td>185</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>214</td>\n",
              "      <td>41</td>\n",
              "      <td>11</td>\n",
              "      <td>69</td>\n",
              "      <td>645</td>\n",
              "      <td>29</td>\n",
              "      <td>716</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>67</td>\n",
              "      <td>7</td>\n",
              "      <td>630</td>\n",
              "      <td>6</td>\n",
              "      <td>144</td>\n",
              "      <td>282</td>\n",
              "      <td>4</td>\n",
              "      <td>180</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>52</td>\n",
              "      <td>1161</td>\n",
              "      <td>27</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>517</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>32</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>124</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>41</td>\n",
              "      <td>542</td>\n",
              "      <td>76</td>\n",
              "      <td>1124</td>\n",
              "      <td>10</td>\n",
              "      <td>1769</td>\n",
              "      <td>7</td>\n",
              "      <td>504</td>\n",
              "      <td>1064</td>\n",
              "      <td>58</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>67</td>\n",
              "      <td>612</td>\n",
              "      <td>13</td>\n",
              "      <td>176</td>\n",
              "      <td>1393</td>\n",
              "      <td>451</td>\n",
              "      <td>81</td>\n",
              "      <td>851</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>225</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>3580</td>\n",
              "      <td>66</td>\n",
              "      <td>168</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>320</td>\n",
              "      <td>285</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>239</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>96</td>\n",
              "      <td>247</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4</td>\n",
              "      <td>317</td>\n",
              "      <td>28</td>\n",
              "      <td>3728</td>\n",
              "      <td>856</td>\n",
              "      <td>81</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "      <td>1975</td>\n",
              "      <td>661</td>\n",
              "      <td>46</td>\n",
              "      <td>54</td>\n",
              "      <td>181</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>2511</td>\n",
              "      <td>24</td>\n",
              "      <td>775</td>\n",
              "      <td>725</td>\n",
              "      <td>10</td>\n",
              "      <td>27</td>\n",
              "      <td>1110</td>\n",
              "      <td>250</td>\n",
              "      <td>27</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>80</td>\n",
              "      <td>3356</td>\n",
              "      <td>45</td>\n",
              "      <td>235</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1640</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>49</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>488</td>\n",
              "      <td>84</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>27</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>1366</td>\n",
              "      <td>49</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>32</td>\n",
              "      <td>172</td>\n",
              "      <td>11</td>\n",
              "      <td>83</td>\n",
              "      <td>126</td>\n",
              "      <td>58</td>\n",
              "      <td>384</td>\n",
              "      <td>194</td>\n",
              "      <td>74</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>1862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>243</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>56</td>\n",
              "      <td>45</td>\n",
              "      <td>58</td>\n",
              "      <td>509</td>\n",
              "      <td>28</td>\n",
              "      <td>276</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>71</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>298</td>\n",
              "      <td>7</td>\n",
              "      <td>107</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>28</td>\n",
              "      <td>322</td>\n",
              "      <td>155</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>437</td>\n",
              "      <td>250</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>57</td>\n",
              "      <td>4306</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>56</td>\n",
              "      <td>478</td>\n",
              "      <td>1922</td>\n",
              "      <td>31</td>\n",
              "      <td>1515</td>\n",
              "      <td>1</td>\n",
              "      <td>3312</td>\n",
              "      <td>12</td>\n",
              "      <td>427</td>\n",
              "      <td>8</td>\n",
              "      <td>211</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>119</td>\n",
              "      <td>42</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>169</td>\n",
              "      <td>5</td>\n",
              "      <td>1728</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>297</td>\n",
              "      <td>360</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>180</td>\n",
              "      <td>495</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>581</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>38</td>\n",
              "      <td>1140</td>\n",
              "      <td>18</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>36</td>\n",
              "      <td>901</td>\n",
              "      <td>3</td>\n",
              "      <td>93</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>88</td>\n",
              "      <td>36</td>\n",
              "      <td>15</td>\n",
              "      <td>389</td>\n",
              "      <td>2500</td>\n",
              "      <td>44</td>\n",
              "      <td>2633</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>139</td>\n",
              "      <td>8</td>\n",
              "      <td>439</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>71</td>\n",
              "      <td>4</td>\n",
              "      <td>1497</td>\n",
              "      <td>77</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>573</td>\n",
              "      <td>487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>56</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>116</td>\n",
              "      <td>28</td>\n",
              "      <td>27</td>\n",
              "      <td>93</td>\n",
              "      <td>286</td>\n",
              "      <td>28</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>44</td>\n",
              "      <td>10</td>\n",
              "      <td>457</td>\n",
              "      <td>1940</td>\n",
              "      <td>41</td>\n",
              "      <td>18</td>\n",
              "      <td>38</td>\n",
              "      <td>93</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>98</td>\n",
              "      <td>1891</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>145</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>141</td>\n",
              "      <td>134</td>\n",
              "      <td>143</td>\n",
              "      <td>5</td>\n",
              "      <td>355</td>\n",
              "      <td>2500</td>\n",
              "      <td>1052</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>172</td>\n",
              "      <td>80</td>\n",
              "      <td>42</td>\n",
              "      <td>55</td>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>12</td>\n",
              "      <td>155</td>\n",
              "      <td>7</td>\n",
              "      <td>55</td>\n",
              "      <td>107</td>\n",
              "      <td>364</td>\n",
              "      <td>264</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>27</td>\n",
              "      <td>42</td>\n",
              "      <td>452</td>\n",
              "      <td>118</td>\n",
              "      <td>102</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>788</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1804</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>1841</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>98</td>\n",
              "      <td>1796</td>\n",
              "      <td>8</td>\n",
              "      <td>57</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>367</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>707</td>\n",
              "      <td>1887</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2571</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>488</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>2158</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5</td>\n",
              "      <td>418</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1220</td>\n",
              "      <td>52</td>\n",
              "      <td>452</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3</td>\n",
              "      <td>2040</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1001</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1476</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>1088</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3110</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>98</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             S_1   S_2   S_3   S_4   S_5  ...  S_28  S_29  S_30  S_31  S_32\n",
              "Time Steps                                ...                              \n",
              "1              2     2     2     2     2  ...     2     2     2     2     2\n",
              "2              4     4     4     4    21  ...     4    16    55    21     4\n",
              "3           4314   178  1585   120   387  ...    53    30    22   106    24\n",
              "4            665    42    55     6    14  ...    34    17  1553    33     9\n",
              "5             13   210    91    29    11  ...    13   130   102    10     6\n",
              "6             27   524    56    15     4  ...     4     6    67   351     4\n",
              "7             55    13    60   165    24  ...   194     4    91     4    26\n",
              "8             11     4     4     4   161  ...    23   284     8   518    23\n",
              "9             35  1283   598   700    55  ...    41   370   185    12    11\n",
              "10            10    11    20   214    41  ...    60     0    71   517   175\n",
              "11            32    22     7    12   124  ...     7    18    18     6    11\n",
              "12             6     4    47     7     4  ...    96   247     9     4   151\n",
              "13             4   317    28  3728   856  ...    80  3356    45   235     4\n",
              "14          1640    10    19    49    15  ...    74     6     4    32  1862\n",
              "15           243     0   128    56    45  ...   250     7     0    71    54\n",
              "16            57  4306     8     6    21  ...     5  1728     5    18     4\n",
              "17            15     0     7     7   297  ...     3    93     3     4   770\n",
              "18            11     8    88    36    15  ...     1   155     1   573   487\n",
              "19            56    21     6   116    28  ...     1     5     1    12    10\n",
              "20            20   145     4    20   141  ...     1     3     1    31   483\n",
              "21            27    42   452   118   102  ...     1     1     1   367     4\n",
              "22           707  1887     5     5  2571  ...     1     1     1     6    39\n",
              "23             5   418     3     3     5  ...     1     1     1     4     5\n",
              "24             3  2040     1     1     3  ...     1     1     1  1001     3\n",
              "25             1    11     1     1     1  ...     1     1     1     5     1\n",
              "26             1     7     1     1     1  ...     1     1     1     3     1\n",
              "27             1  1088     1     1     1  ...     1     1     1     1     1\n",
              "28             1     5     1     1     1  ...     1     1     1     1     1\n",
              "29             1     3     1     1     1  ...     1     1     1     1     1\n",
              "30             1     1     1     1     1  ...     1     1     1     1     1\n",
              "31             1     1     1     1     1  ...     1     1     1     1     1\n",
              "32             1     1     1     1     1  ...     1     1     1     1     1\n",
              "\n",
              "[32 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtkVuHkaT7ba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8db50740-9917-4c37-ecfc-9415c29e1a5c"
      },
      "source": [
        "df_eng_word = pd.DataFrame(columns = [str(\"S_\")+str(x) for x in np.arange(1, 33)])\n",
        "df_eng_word = df_eng_idx.replace(idx_2_word)\n",
        "# df_eng_word.to_csv('/content/Words.csv')\n",
        "df_eng_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S_1</th>\n",
              "      <th>S_2</th>\n",
              "      <th>S_3</th>\n",
              "      <th>S_4</th>\n",
              "      <th>S_5</th>\n",
              "      <th>S_6</th>\n",
              "      <th>S_7</th>\n",
              "      <th>S_8</th>\n",
              "      <th>S_9</th>\n",
              "      <th>S_10</th>\n",
              "      <th>S_11</th>\n",
              "      <th>S_12</th>\n",
              "      <th>S_13</th>\n",
              "      <th>S_14</th>\n",
              "      <th>S_15</th>\n",
              "      <th>S_16</th>\n",
              "      <th>S_17</th>\n",
              "      <th>S_18</th>\n",
              "      <th>S_19</th>\n",
              "      <th>S_20</th>\n",
              "      <th>S_21</th>\n",
              "      <th>S_22</th>\n",
              "      <th>S_23</th>\n",
              "      <th>S_24</th>\n",
              "      <th>S_25</th>\n",
              "      <th>S_26</th>\n",
              "      <th>S_27</th>\n",
              "      <th>S_28</th>\n",
              "      <th>S_29</th>\n",
              "      <th>S_30</th>\n",
              "      <th>S_31</th>\n",
              "      <th>S_32</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time Steps</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>an</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>four</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>two</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>four</td>\n",
              "      <td>two</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>two</td>\n",
              "      <td>child</td>\n",
              "      <td>an</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>proud</td>\n",
              "      <td>dark</td>\n",
              "      <td>redheaded</td>\n",
              "      <td>lady</td>\n",
              "      <td>adult</td>\n",
              "      <td>guy</td>\n",
              "      <td>boy</td>\n",
              "      <td>woman</td>\n",
              "      <td>young</td>\n",
              "      <td>man</td>\n",
              "      <td>men</td>\n",
              "      <td>pitcher</td>\n",
              "      <td>band</td>\n",
              "      <td>group</td>\n",
              "      <td>woman</td>\n",
              "      <td>fisherman</td>\n",
              "      <td>young</td>\n",
              "      <td>children</td>\n",
              "      <td>man</td>\n",
              "      <td>vendor</td>\n",
              "      <td>man</td>\n",
              "      <td>people</td>\n",
              "      <td>men</td>\n",
              "      <td>man</td>\n",
              "      <td>woman</td>\n",
              "      <td>middle</td>\n",
              "      <td>boy</td>\n",
              "      <td>little</td>\n",
              "      <td>men</td>\n",
              "      <td>wearing</td>\n",
              "      <td>asian</td>\n",
              "      <td>young</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>father</td>\n",
              "      <td>-</td>\n",
              "      <td>child</td>\n",
              "      <td>in</td>\n",
              "      <td>woman</td>\n",
              "      <td>walks</td>\n",
              "      <td>in</td>\n",
              "      <td>with</td>\n",
              "      <td>boy</td>\n",
              "      <td>in</td>\n",
              "      <td>are</td>\n",
              "      <td>on</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>in</td>\n",
              "      <td>is</td>\n",
              "      <td>man</td>\n",
              "      <td>playing</td>\n",
              "      <td>and</td>\n",
              "      <td>,</td>\n",
              "      <td>in</td>\n",
              "      <td>wearing</td>\n",
              "      <td>are</td>\n",
              "      <td>in</td>\n",
              "      <td>dressed</td>\n",
              "      <td>-</td>\n",
              "      <td>in</td>\n",
              "      <td>boy</td>\n",
              "      <td>are</td>\n",
              "      <td>fireman</td>\n",
              "      <td>girl</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>with</td>\n",
              "      <td>haired</td>\n",
              "      <td>sits</td>\n",
              "      <td>blue</td>\n",
              "      <td>and</td>\n",
              "      <td>with</td>\n",
              "      <td>swim</td>\n",
              "      <td>a</td>\n",
              "      <td>with</td>\n",
              "      <td>shorts</td>\n",
              "      <td>playing</td>\n",
              "      <td>the</td>\n",
              "      <td>older</td>\n",
              "      <td>people</td>\n",
              "      <td>a</td>\n",
              "      <td>standing</td>\n",
              "      <td>flips</td>\n",
              "      <td>at</td>\n",
              "      <td>a</td>\n",
              "      <td>wearing</td>\n",
              "      <td>a</td>\n",
              "      <td>white</td>\n",
              "      <td>speaking</td>\n",
              "      <td>the</td>\n",
              "      <td>in</td>\n",
              "      <td>aged</td>\n",
              "      <td>gray</td>\n",
              "      <td>with</td>\n",
              "      <td>working</td>\n",
              "      <td>'s</td>\n",
              "      <td>is</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>his</td>\n",
              "      <td>gentleman</td>\n",
              "      <td>looking</td>\n",
              "      <td>,</td>\n",
              "      <td>a</td>\n",
              "      <td>fire</td>\n",
              "      <td>trunks</td>\n",
              "      <td>black</td>\n",
              "      <td>blond</td>\n",
              "      <td>and</td>\n",
              "      <td>soccer</td>\n",
              "      <td>mound</td>\n",
              "      <td>men</td>\n",
              "      <td>are</td>\n",
              "      <td>red</td>\n",
              "      <td>on</td>\n",
              "      <td>up</td>\n",
              "      <td>a</td>\n",
              "      <td>dog</td>\n",
              "      <td>a</td>\n",
              "      <td>green</td>\n",
              "      <td>are</td>\n",
              "      <td>too</td>\n",
              "      <td>blue</td>\n",
              "      <td>a</td>\n",
              "      <td>man</td>\n",
              "      <td>is</td>\n",
              "      <td>a</td>\n",
              "      <td>in</td>\n",
              "      <td>hat</td>\n",
              "      <td>drinking</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>child</td>\n",
              "      <td>with</td>\n",
              "      <td>through</td>\n",
              "      <td>taking</td>\n",
              "      <td>young</td>\n",
              "      <td>in</td>\n",
              "      <td>does</td>\n",
              "      <td>jacket</td>\n",
              "      <td>-</td>\n",
              "      <td>a</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>on</td>\n",
              "      <td>gathered</td>\n",
              "      <td>shirt</td>\n",
              "      <td>some</td>\n",
              "      <td>a</td>\n",
              "      <td>beach</td>\n",
              "      <td>on</td>\n",
              "      <td>large</td>\n",
              "      <td>shirt</td>\n",
              "      <td>on</td>\n",
              "      <td>a</td>\n",
              "      <td>shirt</td>\n",
              "      <td>black</td>\n",
              "      <td>wearing</td>\n",
              "      <td>taking</td>\n",
              "      <td>striped</td>\n",
              "      <td>a</td>\n",
              "      <td>sits</td>\n",
              "      <td>a</td>\n",
              "      <td>black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>and</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>male</td>\n",
              "      <td>his</td>\n",
              "      <td>a</td>\n",
              "      <td>and</td>\n",
              "      <td>hair</td>\n",
              "      <td>hawaiian</td>\n",
              "      <td>two</td>\n",
              "      <td>number</td>\n",
              "      <td>stage</td>\n",
              "      <td>together</td>\n",
              "      <td>and</td>\n",
              "      <td>rocks</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>,</td>\n",
              "      <td>a</td>\n",
              "      <td>-</td>\n",
              "      <td>is</td>\n",
              "      <td>a</td>\n",
              "      <td>woman</td>\n",
              "      <td>is</td>\n",
              "      <td>top</td>\n",
              "      <td>a</td>\n",
              "      <td>pictures</td>\n",
              "      <td>shirt</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>on</td>\n",
              "      <td>cup</td>\n",
              "      <td>shirt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>dog</td>\n",
              "      <td>mustache</td>\n",
              "      <td>railing</td>\n",
              "      <td>close</td>\n",
              "      <td>child</td>\n",
              "      <td>hand</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>black</td>\n",
              "      <td>and</td>\n",
              "      <td>shirt</td>\n",
              "      <td>in</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>smiling</td>\n",
              "      <td>and</td>\n",
              "      <td>purple</td>\n",
              "      <td>by</td>\n",
              "      <td>'</td>\n",
              "      <td>one</td>\n",
              "      <td>park</td>\n",
              "      <td>brimmed</td>\n",
              "      <td>carrying</td>\n",
              "      <td>small</td>\n",
              "      <td>outside</td>\n",
              "      <td>playing</td>\n",
              "      <td>and</td>\n",
              "      <td>blue</td>\n",
              "      <td>of</td>\n",
              "      <td>walking</td>\n",
              "      <td>preparing</td>\n",
              "      <td>ground</td>\n",
              "      <td>of</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>is</td>\n",
              "      <td>and</td>\n",
              "      <td>at</td>\n",
              "      <td>look</td>\n",
              "      <td>walking</td>\n",
              "      <td>and</td>\n",
              "      <td>into</td>\n",
              "      <td>purse</td>\n",
              "      <td>blue</td>\n",
              "      <td>leans</td>\n",
              "      <td>white</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "      <td>in</td>\n",
              "      <td>hat</td>\n",
              "      <td>the</td>\n",
              "      <td>mask</td>\n",
              "      <td>in</td>\n",
              "      <td>bench</td>\n",
              "      <td>tan</td>\n",
              "      <td>a</td>\n",
              "      <td>boat</td>\n",
              "      <td>,</td>\n",
              "      <td>a</td>\n",
              "      <td>green</td>\n",
              "      <td>hooded</td>\n",
              "      <td>his</td>\n",
              "      <td>through</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>next</td>\n",
              "      <td>coffee</td>\n",
              "      <td>jeans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>sitting</td>\n",
              "      <td>wearing</td>\n",
              "      <td>the</td>\n",
              "      <td>of</td>\n",
              "      <td>along</td>\n",
              "      <td>a</td>\n",
              "      <td>the</td>\n",
              "      <td>walking</td>\n",
              "      <td>eyes</td>\n",
              "      <td>over</td>\n",
              "      <td>jerseys</td>\n",
              "      <td>is</td>\n",
              "      <td>clapping</td>\n",
              "      <td>the</td>\n",
              "      <td>carries</td>\n",
              "      <td>sea</td>\n",
              "      <td>as</td>\n",
              "      <td>pink</td>\n",
              "      <td>in</td>\n",
              "      <td>hat</td>\n",
              "      <td>basket</td>\n",
              "      <td>with</td>\n",
              "      <td>there</td>\n",
              "      <td>song</td>\n",
              "      <td>skirt</td>\n",
              "      <td>jacket</td>\n",
              "      <td>friend</td>\n",
              "      <td>the</td>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>in</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>in</td>\n",
              "      <td>a</td>\n",
              "      <td>water</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>ocean</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>stands</td>\n",
              "      <td>the</td>\n",
              "      <td>,</td>\n",
              "      <td>poised</td>\n",
              "      <td>their</td>\n",
              "      <td>middle</td>\n",
              "      <td>a</td>\n",
              "      <td>,</td>\n",
              "      <td>a</td>\n",
              "      <td>,</td>\n",
              "      <td>the</td>\n",
              "      <td>,</td>\n",
              "      <td>above</td>\n",
              "      <td>others</td>\n",
              "      <td>are</td>\n",
              "      <td>on</td>\n",
              "      <td>dancing</td>\n",
              "      <td>and</td>\n",
              "      <td>in</td>\n",
              "      <td>grass</td>\n",
              "      <td>be</td>\n",
              "      <td>man</td>\n",
              "      <td>a</td>\n",
              "      <td>carrying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>a</td>\n",
              "      <td>sweater</td>\n",
              "      <td>while</td>\n",
              "      <td>surroundings</td>\n",
              "      <td>pier</td>\n",
              "      <td>jacket</td>\n",
              "      <td>while</td>\n",
              "      <td>the</td>\n",
              "      <td>amidst</td>\n",
              "      <td>rail</td>\n",
              "      <td>one</td>\n",
              "      <td>for</td>\n",
              "      <td>hands</td>\n",
              "      <td>a</td>\n",
              "      <td>blue</td>\n",
              "      <td>illuminated</td>\n",
              "      <td>young</td>\n",
              "      <td>drawing</td>\n",
              "      <td>foreground</td>\n",
              "      <td>is</td>\n",
              "      <td>his</td>\n",
              "      <td>boats</td>\n",
              "      <td>trees</td>\n",
              "      <td>his</td>\n",
              "      <td>,</td>\n",
              "      <td>a</td>\n",
              "      <td>the</td>\n",
              "      <td>near</td>\n",
              "      <td>cooked</td>\n",
              "      <td>holding</td>\n",
              "      <td>restaurant</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>lounge</td>\n",
              "      <td>is</td>\n",
              "      <td>people</td>\n",
              "      <td>by</td>\n",
              "      <td>,</td>\n",
              "      <td>on</td>\n",
              "      <td>mountains</td>\n",
              "      <td>sidewalk</td>\n",
              "      <td>a</td>\n",
              "      <td>of</td>\n",
              "      <td>in</td>\n",
              "      <td>his</td>\n",
              "      <td>.</td>\n",
              "      <td>woman</td>\n",
              "      <td>container</td>\n",
              "      <td>by</td>\n",
              "      <td>girl</td>\n",
              "      <td>in</td>\n",
              "      <td>,</td>\n",
              "      <td>sitting</td>\n",
              "      <td>head</td>\n",
              "      <td>and</td>\n",
              "      <td>around</td>\n",
              "      <td>guitar</td>\n",
              "      <td>as</td>\n",
              "      <td>plaid</td>\n",
              "      <td>striped</td>\n",
              "      <td>some</td>\n",
              "      <td>in</td>\n",
              "      <td>a</td>\n",
              "      <td>sitting</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>chair</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>play</td>\n",
              "      <td>looking</td>\n",
              "      <td>holding</td>\n",
              "      <td>as</td>\n",
              "      <td>show</td>\n",
              "      <td>while</td>\n",
              "      <td>truck</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>next</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>is</td>\n",
              "      <td>full</td>\n",
              "      <td>the</td>\n",
              "      <td>looks</td>\n",
              "      <td>the</td>\n",
              "      <td>with</td>\n",
              "      <td>on</td>\n",
              "      <td>while</td>\n",
              "      <td>run</td>\n",
              "      <td>them</td>\n",
              "      <td>while</td>\n",
              "      <td>a</td>\n",
              "      <td>hat</td>\n",
              "      <td>sweatshirt</td>\n",
              "      <td>trees</td>\n",
              "      <td>the</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>next</td>\n",
              "      <td>for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>outside</td>\n",
              "      <td>pressing</td>\n",
              "      <td>on</td>\n",
              "      <td>in</td>\n",
              "      <td>an</td>\n",
              "      <td>two</td>\n",
              "      <td>through</td>\n",
              "      <td>looking</td>\n",
              "      <td>bed</td>\n",
              "      <td>pilot</td>\n",
              "      <td>red</td>\n",
              "      <td>pitch</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>bringing</td>\n",
              "      <td>of</td>\n",
              "      <td>sun</td>\n",
              "      <td>on</td>\n",
              "      <td>sand</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>talking</td>\n",
              "      <td>-</td>\n",
              "      <td>and</td>\n",
              "      <td>a</td>\n",
              "      <td>man</td>\n",
              "      <td>is</td>\n",
              "      <td>doing</td>\n",
              "      <td>.</td>\n",
              "      <td>oven</td>\n",
              "      <td>.</td>\n",
              "      <td>to</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>,</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>umbrella</td>\n",
              "      <td>guys</td>\n",
              "      <td>the</td>\n",
              "      <td>at</td>\n",
              "      <td>of</td>\n",
              "      <td>boat</td>\n",
              "      <td>jersey</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>her</td>\n",
              "      <td>items</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "      <td>group</td>\n",
              "      <td>stool</td>\n",
              "      <td>to</td>\n",
              "      <td>down</td>\n",
              "      <td>a</td>\n",
              "      <td>woman</td>\n",
              "      <td>in</td>\n",
              "      <td>standing</td>\n",
              "      <td>tricks</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>behind</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>a</td>\n",
              "      <td>musical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>and</td>\n",
              "      <td>on</td>\n",
              "      <td>beach</td>\n",
              "      <td>standing</td>\n",
              "      <td>,</td>\n",
              "      <td>take</td>\n",
              "      <td>fog</td>\n",
              "      <td>her</td>\n",
              "      <td>watermelons</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>hand</td>\n",
              "      <td>on</td>\n",
              "      <td>which</td>\n",
              "      <td>a</td>\n",
              "      <td>the</td>\n",
              "      <td>of</td>\n",
              "      <td>next</td>\n",
              "      <td>a</td>\n",
              "      <td>houses</td>\n",
              "      <td>building</td>\n",
              "      <td>and</td>\n",
              "      <td>the</td>\n",
              "      <td>with</td>\n",
              "      <td>on</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>them</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>bunch</td>\n",
              "      <td>instrument</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>looking</td>\n",
              "      <td>an</td>\n",
              "      <td>in</td>\n",
              "      <td>camera</td>\n",
              "      <td>while</td>\n",
              "      <td>his</td>\n",
              "      <td>behind</td>\n",
              "      <td>cellphone</td>\n",
              "      <td>while</td>\n",
              "      <td>with</td>\n",
              "      <td>a</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>to</td>\n",
              "      <td>her</td>\n",
              "      <td>is</td>\n",
              "      <td>six</td>\n",
              "      <td>second</td>\n",
              "      <td>walking</td>\n",
              "      <td>to</td>\n",
              "      <td>group</td>\n",
              "      <td>behind</td>\n",
              "      <td>in</td>\n",
              "      <td>a</td>\n",
              "      <td>background</td>\n",
              "      <td>folded</td>\n",
              "      <td>his</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>of</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>at</td>\n",
              "      <td>old</td>\n",
              "      <td>a</td>\n",
              "      <td>at</td>\n",
              "      <td>it</td>\n",
              "      <td>picture</td>\n",
              "      <td>him</td>\n",
              "      <td>.</td>\n",
              "      <td>family</td>\n",
              "      <td>fog</td>\n",
              "      <td>goalie</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>near</td>\n",
              "      <td>-</td>\n",
              "      <td>child</td>\n",
              "      <td>people</td>\n",
              "      <td>his</td>\n",
              "      <td>of</td>\n",
              "      <td>them</td>\n",
              "      <td>the</td>\n",
              "      <td>child</td>\n",
              "      <td>looks</td>\n",
              "      <td>arms</td>\n",
              "      <td>skateboard</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>red</td>\n",
              "      <td>crossing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>his</td>\n",
              "      <td>-</td>\n",
              "      <td>distance</td>\n",
              "      <td>park</td>\n",
              "      <td>'s</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>members</td>\n",
              "      <td>and</td>\n",
              "      <td>in</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>face</td>\n",
              "      <td>.</td>\n",
              "      <td>the</td>\n",
              "      <td>pack</td>\n",
              "      <td>,</td>\n",
              "      <td>in</td>\n",
              "      <td>wares</td>\n",
              "      <td>people</td>\n",
              "      <td>.</td>\n",
              "      <td>background</td>\n",
              "      <td>listen</td>\n",
              "      <td>on</td>\n",
              "      <td>outside</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>flowers</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>son</td>\n",
              "      <td>fashioned</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>raining</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>stand</td>\n",
              "      <td>mountains</td>\n",
              "      <td>the</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>of</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>horizon</td>\n",
              "      <td>,</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>a</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>in</td>\n",
              "      <td>street</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>.</td>\n",
              "      <td>computer</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "      <td>background</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>a</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>barbecue</td>\n",
              "      <td>green</td>\n",
              "      <td>distance</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>city</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>a</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>monitor</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>man</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>building</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>pot</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>and</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>background</td>\n",
              "      <td>background</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>and</td>\n",
              "      <td>standing</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>chalk</td>\n",
              "      <td>in</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>keyboard</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>message</td>\n",
              "      <td>the</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>in</td>\n",
              "      <td>water</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>background</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                S_1        S_2        S_3  ...     S_30        S_31        S_32\n",
              "Time Steps                                 ...                                 \n",
              "1             <sos>      <sos>      <sos>  ...    <sos>       <sos>       <sos>\n",
              "2                 a          a          a  ...    child          an           a\n",
              "3             proud       dark  redheaded  ...  wearing       asian       young\n",
              "4            father          -      child  ...  fireman        girl         man\n",
              "5              with     haired       sits  ...       's          is          in\n",
              "6               his  gentleman    looking  ...      hat    drinking           a\n",
              "7             child       with    through  ...     sits           a       black\n",
              "8               and          a          a  ...       on         cup       shirt\n",
              "9               dog   mustache    railing  ...   ground          of         and\n",
              "10               is        and         at  ...     next      coffee       jeans\n",
              "11          sitting    wearing        the  ...       to          in         and\n",
              "12               in          a      water  ...      man           a    carrying\n",
              "13                a    sweater      while  ...  holding  restaurant           a\n",
              "14           lounge         is     people  ...        a     sitting        case\n",
              "15            chair      <unk>       play  ...    <unk>        next         for\n",
              "16          outside   pressing         on  ...        .          to           a\n",
              "17                ,      <unk>        the  ...    <eos>           a     musical\n",
              "18              and         on      beach  ...    <pad>       bunch  instrument\n",
              "19          looking         an         in  ...    <pad>          of          is\n",
              "20               at        old          a  ...    <pad>         red    crossing\n",
              "21              his          -   distance  ...    <pad>     flowers           a\n",
              "22              son  fashioned          .  ...    <pad>          in      street\n",
              "23                .   computer      <eos>  ...    <pad>           a           .\n",
              "24            <eos>    monitor      <pad>  ...    <pad>         pot       <eos>\n",
              "25            <pad>        and      <pad>  ...    <pad>           .       <pad>\n",
              "26            <pad>        the      <pad>  ...    <pad>       <eos>       <pad>\n",
              "27            <pad>   keyboard      <pad>  ...    <pad>       <pad>       <pad>\n",
              "28            <pad>          .      <pad>  ...    <pad>       <pad>       <pad>\n",
              "29            <pad>      <eos>      <pad>  ...    <pad>       <pad>       <pad>\n",
              "30            <pad>      <pad>      <pad>  ...    <pad>       <pad>       <pad>\n",
              "31            <pad>      <pad>      <pad>  ...    <pad>       <pad>       <pad>\n",
              "32            <pad>      <pad>      <pad>  ...    <pad>       <pad>       <pad>\n",
              "\n",
              "[32 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0sxi0e0lkvK",
        "colab_type": "text"
      },
      "source": [
        "# 3. Long Short Term Memory (LSTM) - Under the Hood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL7l0Fj-lcng",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/2560/1*sQBwBtwCwqqXY0k5O0ZvMg.png\">\n",
        "\n",
        "## The above picture shows the units present under a single LSTM Cell. I will add some references to learn more about LSTM in the last and why it works well for long sequences.\n",
        "\n",
        "## But to simply put, Vanilla RNN, Gated Recurrent Unit (GRU) is not able to capture the long term dependencies due to its nature of design and suffers heavily by the Vanishing Gradient problem, which makes the rate of change in weights and bias values negligible, resulting in poor generalization.\n",
        "\n",
        "## But LSTM has some special units called gates (Remember gate, Forget gate, Update gate), which helps to overcome the problems stated before.\n",
        "\n",
        "## Inside the LSTM cell, we have a bunch of mini neural networks with sigmoid and TanH activations at the final layer and few vector adder, Concat, multiplications operations.\n",
        "\n",
        "1. Sigmoid NN → Squishes the values between 0 and 1. Say a value closer to 0 means to forget and a value closer to 1 means to remember.\n",
        "\n",
        "2. Embedding NN → Converts the input word indices into word embedding.\n",
        "\n",
        "3. TanH NN → Squishes the values between -1 and 1. Helps to regulate the vector values from either getting exploded to the maximum or shrank to the minimum.\n",
        "\n",
        "4. The hidden state and the cell state are referred to here as the context vector, which are the outputs from the LSTM cell. The input is the sentence's numerical indexes fed into the embedding NN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ef7R9ZGy7Ca",
        "colab_type": "text"
      },
      "source": [
        "# 4. Encoder Model Architecture (Seq2Seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFPrrZlAp-8o",
        "colab_type": "text"
      },
      "source": [
        "## Before moving to seq2seq model, we need to create Encoder ,Decoder and create a interface between them in the seq2seq model.\n",
        "\n",
        "## Let's pass the german input sequence \"Ich liebe tief lernen\" which translates to \"I love deep learning\" in english.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMvkk_AM1orm",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*aNcybCTdPlrXsCwIo1OfTg.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj94RR0ZYizi",
        "colab_type": "text"
      },
      "source": [
        "## For a lighter note, let's explain the process happening in the above image. The Encoder of the Seq2Seq model takes one input at a time. Our input German word sequence is \"ich Liebe Tief Lernen\".\n",
        "\n",
        "## Also, we append the start of sequence \"SOS\" and the end of sentence \"EOS\" tokens in the starting and in the ending of the input sentence.\n",
        "\n",
        "## Therefore at \n",
        "## At time step-0, the \"SOS\" token is sent,\n",
        "## At time step-1 the token \"ich\" is sent,\n",
        "## At time step-2 the token \"Liebe\" is sent,\n",
        "## At time step-3 the token \"Tief\" is sent,\n",
        "## At time step-4 the token \"Lernen\" is sent,\n",
        "## At time step-4 the token \"EOS\" is sent.\n",
        "\n",
        "## And the first block in the Encoder architecture is the word embedding layer [shown in green block], which converts the input indexed word into a dense vector representation called word embedding (sizes - 100/200/300).\n",
        "\n",
        "## Then our word embedding vector is sent to the LSTM cell, where it is combined with the hidden state (hs), and the cell state (cs) of the previous time step and the encoder block outputs a new hs and a cs which is passed to the next LSTM  cell. \n",
        "\n",
        "## It is understood that the hs and cs captured some vector representation of the sentence so far.\n",
        "\n",
        "## At time step-0, the hidden state and cell state are either initialized fully of zeros or random numbers.\n",
        "\n",
        "## Then after we sent pass all our input german word sequence, a context vector [shown in yellow block] (hs, cs) is finally obtained, which is a dense representation of the word sequence and can be sent to the decoder's first LSTM (hs, cs) for the corresponding English translation.\n",
        "\n",
        "## In the above figure, we use 2 layer LSTM  architecture, where we connect the first LSTM to the second LSTM and we then we obtain 2 context vectors stacked on top as the final output.\n",
        "\n",
        "## It is a must that we design identical encoder and decoder blocks in the seq2seq model.\n",
        "\n",
        "## The above visualization is applicable for a single sentence from a batch. Say we have a batch size of 5 (Experimental), then we pass 5 sentences at a time to the Encoder, which looks like the below figure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wDhJhtXd1zL",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*xP8MgIfKwjStFDUo0_W3QA.png\">\n",
        "\n",
        "##  The same concept is extended to a batch size of 5 (experimental), where we consider 5 input sentences and the first token from each sentences is sent to the encoder at a time. Each sequences in the batch is maintained to have the same length using the padding token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbfs74GwmKcq",
        "colab_type": "text"
      },
      "source": [
        "# 5. Encoder Code Implementation (Seq2Seq)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vlOtY31y40q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "58a0f92e-7d38-43ee-9d10-b8eb06f62ffe"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    #self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    #self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    \n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    \n",
        "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "\n",
        "    return hidden_state, cell_state\n",
        "\n",
        "input_size_encoder = len(german.vocab)\n",
        "encoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "encoder_dropout = 0.5\n",
        "\n",
        "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
        "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
        "print(encoder_lstm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(5376, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bm8AObR4U9X",
        "colab_type": "text"
      },
      "source": [
        "# 6. Decoder Model Architecture (Seq2Seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDSnNEG6iAO3",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/800/1*FtDDCniBMb8HXYEM6PRohQ.png\">\n",
        "\n",
        "## The decoder also does a single step at a time.\n",
        "\n",
        "## The Context Vector from the Encoder block is provided as the hidden state (hs) and cell state (cs) for the decoder's first LSTM block.\n",
        "\n",
        "## The start of the sentence \"SOS\"  token is passed to the embedding NN, then passed to the first LSTM cell of the decoder, and finally, it is passed through a linear layer [Shown in Pink color], which provides an output English token prediction probabilities (4556 Probabilities), hidden state (hs), Cell State (cs). \n",
        "\n",
        "## The output word with the highest probability is chosen, hidden state (hs), Cell State (cs) is passed as the inputs to the next LSTM cell and this process is executed until it reaches the end of sentences \"EOS\".\n",
        "\n",
        "## The subsequent layers will use the hidden and cell state from the previous time steps.\n",
        "\n",
        "## The above visualization is applicable for a single sentence from a batch. Say we have a batch size of 5 (Experimental), then we pass 5 sentences at a time to the Encoder, which provide 5 sets of Context Vectors, and they all are passed into the Decoder, which looks like the below figure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V1yo6_tkL_o",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/2560/1*UPyGSZSuIQ52IjyFdPpm6A.png\">\n",
        "\n",
        "# The same concept is extended to a batch size of 5 (experimental), where we consider 5 input encoder's context vectors and the first token <\"sos\"> is sent to the decoder at a time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIhD2-OBmVnS",
        "colab_type": "text"
      },
      "source": [
        "# 7. Decoder Code Implementation (Seq2Seq)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnGwwU6p2Zfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0b6caa95-b495-4ca5-8075-7f86fd9ef1a6"
      },
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    #self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    #self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  # Shape of x (32) [batch_size]\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "\n",
        "    # Shape of x (1, 32) [1, batch_size]\n",
        "    x = x.unsqueeze(0)\n",
        "\n",
        "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "    # Shape --> outputs (1, 32, 1024) [1, batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "\n",
        "    # Shape --> predictions (1, 32, 4556) [ 1, batch_size , output_size]\n",
        "    predictions = self.fc(outputs)\n",
        "\n",
        "    # Shape --> predictions (32, 4556) [batch_size , output_size]\n",
        "    predictions = predictions.squeeze(0)\n",
        "\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = len(english.vocab)\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "decoder_dropout = 0.5\n",
        "output_size = len(english.vocab)\n",
        "\n",
        "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
        "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
        "print(decoder_lstm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(4556, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "  (fc): Linear(in_features=1024, out_features=4556, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sok8t_j76Ozp",
        "colab_type": "text"
      },
      "source": [
        "# 8. Seq2Seq (Encoder + Decoder) Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZcNPOpB_DeW",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*d9kP4XoWGnIcmyhX-g4Xvw.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYYkTeNokhRu",
        "colab_type": "text"
      },
      "source": [
        "## The final seq2seq implementation looks like the figure above.\n",
        "\n",
        "## 1. Provide both input (German) and output (English) sentences.\n",
        "## 2. Pass the input sequence to the encoder and extract context vectors.\n",
        "## 3. Pass the output sequence to the decoder, context vecotr from encoder to produce the predicted output sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhJZFJxG_HbA",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*7SVU_REkIUALmegTbFI9Fw.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0rHNbZe7ALr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "182d7e9d-f29a-4741-8aec-1653bfb4173d"
      },
      "source": [
        "for batch in train_iterator:\n",
        "  print(batch.src.shape)\n",
        "  print(batch.trg.shape)\n",
        "  break\n",
        "\n",
        "x = batch.trg[1]\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([21, 32])\n",
            "torch.Size([25, 32])\n",
            "tensor([  16,    4,  500,   21,   70,    4,  176,    4,    4,    4,    9,    4,\n",
            "         209,  691,    4,    4,    4,    9, 2208,    4,    7,    4,    4,    4,\n",
            "         209,   16,    4,    4,  417,   48,  113,    4], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3al--sEzmfmU",
        "colab_type": "text"
      },
      "source": [
        "# 9. Seq2Seq (Encoder + Decoder) Code Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuHGodQe4r9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.Encoder_LSTM = Encoder_LSTM\n",
        "    self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "  def forward(self, source, target, tfr=0.5):\n",
        "    # Shape - Source : (10, 32) [(Sentence length German + some padding), Number of Sentences]\n",
        "    batch_size = source.shape[1]\n",
        "\n",
        "    # Shape - Source : (14, 32) [(Sentence length English + some padding), Number of Sentences]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(english.vocab)\n",
        "    \n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
        "    hidden_state, cell_state = self.Encoder_LSTM(source)\n",
        "\n",
        "    # Shape of x (32 elements)\n",
        "    x = target[0] # Trigger token <SOS>\n",
        "\n",
        "    for i in range(1, target_len):\n",
        "      # Shape --> output (32, 5766) \n",
        "      output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
        "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOQL9vk49H2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0\n",
        "\n",
        "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpsjQCsZ_srZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e12c9dd4-f0d2-4138-9eaf-2b6595deb101"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (Encoder_LSTM): EncoderLSTM(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(5376, 300)\n",
              "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
              "  )\n",
              "  (Decoder_LSTM): DecoderLSTM(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(4556, 300)\n",
              "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
              "    (fc): Linear(in_features=1024, out_features=4556, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtH0Bnq3qFmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
        "    spacy_ger = spacy.load(\"de\")\n",
        "\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "    tokens.insert(0, german.init_token)\n",
        "    tokens.append(german.eos_token)\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
        "\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "    return translated_sentence[1:]\n",
        "\n",
        "def bleu(data, model, german, english, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = vars(example)[\"src\"]\n",
        "        trg = vars(example)[\"trg\"]\n",
        "\n",
        "        prediction = translate_sentence(model, src, german, english, device)\n",
        "        prediction = prediction[:-1]  # remove <eos> token\n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)\n",
        "\n",
        "def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n",
        "    print('saving')\n",
        "    print()\n",
        "    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n",
        "    torch.save(state, '/content/checkpoint-NMT')\n",
        "    torch.save(model.state_dict(),'/content/checkpoint-NMT-SD')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6VnFyCnNlTz",
        "colab_type": "text"
      },
      "source": [
        "# 10. Seq2Seq Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4jLBPRD9osT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a9baa27-1492-4cae-b2a7-f42b0e2e316d"
      },
      "source": [
        "|epoch_loss = 0.0\n",
        "num_epochs = 100\n",
        "best_loss = 999999\n",
        "best_epoch = -1\n",
        "sentence1 = \"ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster\"\n",
        "ts1  = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "  model.eval()\n",
        "  translated_sentence1 = translate_sentence(model, sentence1, german, english, device, max_length=50)\n",
        "  print(f\"Translated example sentence 1: \\n {translated_sentence1}\")\n",
        "  ts1.append(translated_sentence1)\n",
        "\n",
        "  model.train(True)\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "    input = batch.src.to(device)\n",
        "    target = batch.trg.to(device)\n",
        "\n",
        "    # Pass the input and target for model's forward method\n",
        "    output = model(input, target)\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    # Clear the accumulating gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Calculate the loss value for every epoch\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # Calculate the gradients for weights & biases using back-propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip the gradient value is it exceeds > 1\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "    # Update the weights values using the gradients we calculated using bp \n",
        "    optimizer.step()\n",
        "    step += 1\n",
        "    epoch_loss += loss.item()\n",
        "    writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "\n",
        "  if epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    best_epoch = epoch\n",
        "    checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss) \n",
        "    if ((epoch - best_epoch) >= 10):\n",
        "      print(\"no improvement in 10 epochs, break\")\n",
        "      break\n",
        "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "  print()\n",
        "  \n",
        "print(epoch_loss / len(train_iterator))\n",
        "\n",
        "score = bleu(test_data[1:100], model, german, english, device)\n",
        "print(f\"Bleu score {score*100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 1 / 100\n",
            "Translated example sentence 1: \n",
            " ['yo', 'yo', 'talkie', 'warm', 'warm', 'sunhats', 'missing', 'location', 'barbecuing', 'radio', 'wilderness', 'kayaking', 'uniform', 'wii', 'squatting', 'yo', 'yo', 'talkie', '4', '4', '4', '4', 'backward', 'backward', '4', 'landscape', 'buffet', 'fast', 'sunbathers', 'shoveling', 'shoveling', 'tugging', 'tugging', 'tugging', 'flags', 'sacks', 'sacks', 'sacks', 'wooded', 'horses', 'horses', 'tends', 'tends', 'tends', 'wade', 'wade', 'drill', 'drill', 'softball', 'drill']\n",
            "saving\n",
            "\n",
            "Epoch_Loss - 3.9891204833984375\n",
            "\n",
            "Epoch - 2 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
            "Epoch_Loss - 3.4609951972961426\n",
            "\n",
            "Epoch - 3 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
            "Epoch_Loss - 3.449892044067383\n",
            "\n",
            "Epoch - 4 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'a', 'of', 'a', '.', '<eos>']\n",
            "Epoch_Loss - 3.193593740463257\n",
            "\n",
            "Epoch - 5 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'wall', '.', '<eos>']\n",
            "Epoch_Loss - 3.512390375137329\n",
            "\n",
            "Epoch - 6 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', '.', '<eos>']\n",
            "Epoch_Loss - 2.0059382915496826\n",
            "\n",
            "Epoch - 7 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'looking', 'at', 'a', 'book', '.', '<eos>']\n",
            "Epoch_Loss - 3.1218972206115723\n",
            "\n",
            "Epoch - 8 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', '.', '<eos>']\n",
            "Epoch_Loss - 2.366042375564575\n",
            "\n",
            "Epoch - 9 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'painting', 'a', 'book', '.', '<eos>']\n",
            "Epoch_Loss - 1.6029590368270874\n",
            "\n",
            "Epoch - 10 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'podium', 'painting', 'a', 'a', '.', '<eos>']\n",
            "Epoch_Loss - 2.7806849479675293\n",
            "\n",
            "Epoch - 11 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'painting', 'a', 'sign', '.', '<eos>']\n",
            "Epoch_Loss - 2.943093776702881\n",
            "\n",
            "Epoch - 12 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'painting', 'a', 'train', '.', '<eos>']\n",
            "Epoch_Loss - 3.4859936237335205\n",
            "\n",
            "Epoch - 13 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'painting', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 2.1539034843444824\n",
            "\n",
            "Epoch - 14 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', '.', '<eos>']\n",
            "Epoch_Loss - 1.650160789489746\n",
            "\n",
            "Epoch - 15 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', '.', '<eos>']\n",
            "Epoch_Loss - 2.4137518405914307\n",
            "\n",
            "Epoch - 16 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', '.', '<eos>']\n",
            "Epoch_Loss - 2.623554229736328\n",
            "\n",
            "Epoch - 17 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'a', 'ladder', 'painting', 'a', 'sign', '.', '<eos>']\n",
            "Epoch_Loss - 0.9484565258026123\n",
            "\n",
            "Epoch - 18 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'painting', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.5044070482254028\n",
            "\n",
            "Epoch - 19 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.8556140065193176\n",
            "\n",
            "Epoch - 20 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.3060773611068726\n",
            "\n",
            "Epoch - 21 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.917847990989685\n",
            "\n",
            "Epoch - 22 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 2.997354030609131\n",
            "\n",
            "Epoch - 23 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.8359497785568237\n",
            "\n",
            "Epoch - 24 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.6619189977645874\n",
            "\n",
            "Epoch - 25 / 100\n",
            "Translated example sentence 1: \n",
            " ['man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.3125892877578735\n",
            "\n",
            "Epoch - 26 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.4950593709945679\n",
            "\n",
            "Epoch - 27 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.038191556930542\n",
            "\n",
            "Epoch - 28 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.6825821995735168\n",
            "\n",
            "Epoch - 29 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.9062373638153076\n",
            "\n",
            "Epoch - 30 / 100\n",
            "Translated example sentence 1: \n",
            " ['man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.7665305137634277\n",
            "\n",
            "Epoch - 31 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.3129847049713135\n",
            "\n",
            "Epoch - 32 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'painting', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.59452223777771\n",
            "\n",
            "Epoch - 33 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.554878294467926\n",
            "\n",
            "Epoch - 34 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.0838985443115234\n",
            "\n",
            "Epoch - 35 / 100\n",
            "Translated example sentence 1: \n",
            " ['man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.207323670387268\n",
            "\n",
            "Epoch - 36 / 100\n",
            "Translated example sentence 1: \n",
            " ['man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.7906355261802673\n",
            "\n",
            "Epoch - 37 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.517241895198822\n",
            "\n",
            "Epoch - 38 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.46325913071632385\n",
            "\n",
            "Epoch - 39 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'building', '.', '<eos>']\n",
            "Epoch_Loss - 0.4778721332550049\n",
            "\n",
            "Epoch - 40 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.5813856720924377\n",
            "\n",
            "Epoch - 41 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.8279156684875488\n",
            "\n",
            "Epoch - 42 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.5408395528793335\n",
            "\n",
            "Epoch - 43 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.8749784231185913\n",
            "\n",
            "Epoch - 44 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.42627134919166565\n",
            "\n",
            "Epoch - 45 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.875438928604126\n",
            "\n",
            "Epoch - 46 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.8031521439552307\n",
            "\n",
            "Epoch - 47 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.318734049797058\n",
            "\n",
            "Epoch - 48 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.7978665828704834\n",
            "\n",
            "Epoch - 49 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'reading', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.7330925464630127\n",
            "\n",
            "Epoch - 50 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'ladder', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.548840343952179\n",
            "\n",
            "Epoch - 51 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.18946675956249237\n",
            "\n",
            "Epoch - 52 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.9799064993858337\n",
            "\n",
            "Epoch - 53 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.2598234713077545\n",
            "\n",
            "Epoch - 54 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.8249617218971252\n",
            "\n",
            "Epoch - 55 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.7612940073013306\n",
            "\n",
            "Epoch - 56 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.29659953713417053\n",
            "\n",
            "Epoch - 57 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.43488651514053345\n",
            "\n",
            "Epoch - 58 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.38553211092948914\n",
            "\n",
            "Epoch - 59 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.24913769960403442\n",
            "\n",
            "Epoch - 60 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.36423182487487793\n",
            "\n",
            "Epoch - 61 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.47497814893722534\n",
            "\n",
            "Epoch - 62 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.230508804321289\n",
            "\n",
            "Epoch - 63 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.5316182374954224\n",
            "\n",
            "Epoch - 64 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.18439343571662903\n",
            "\n",
            "Epoch - 65 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.4218553602695465\n",
            "\n",
            "Epoch - 66 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.7870435118675232\n",
            "\n",
            "Epoch - 67 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'a', 'ladder', 'painting', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.49428510665893555\n",
            "\n",
            "Epoch - 68 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.605211615562439\n",
            "\n",
            "Epoch - 69 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.27178558707237244\n",
            "\n",
            "Epoch - 70 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.31921255588531494\n",
            "\n",
            "Epoch - 71 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.6440503597259521\n",
            "\n",
            "Epoch - 72 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.23545381426811218\n",
            "\n",
            "Epoch - 73 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.5661376714706421\n",
            "\n",
            "Epoch - 74 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.24639709293842316\n",
            "\n",
            "Epoch - 75 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.946926474571228\n",
            "\n",
            "Epoch - 76 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.3368785083293915\n",
            "\n",
            "Epoch - 77 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.2710837125778198\n",
            "\n",
            "Epoch - 78 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.2729235291481018\n",
            "\n",
            "Epoch - 79 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.5074217915534973\n",
            "\n",
            "Epoch - 80 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'ladder', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.37556785345077515\n",
            "\n",
            "Epoch - 81 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.6220839619636536\n",
            "\n",
            "Epoch - 82 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.32914605736732483\n",
            "\n",
            "Epoch - 83 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.3966521620750427\n",
            "\n",
            "Epoch - 84 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.20182645320892334\n",
            "\n",
            "Epoch - 85 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.9648104906082153\n",
            "\n",
            "Epoch - 86 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.6514857411384583\n",
            "\n",
            "Epoch - 87 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.26174861192703247\n",
            "\n",
            "Epoch - 88 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'a', 'ladder', 'overlooking', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.2700582444667816\n",
            "\n",
            "Epoch - 89 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.3981388807296753\n",
            "\n",
            "Epoch - 90 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.432936668395996\n",
            "\n",
            "Epoch - 91 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.1688262224197388\n",
            "\n",
            "Epoch - 92 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.1299320459365845\n",
            "\n",
            "Epoch - 93 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.23126237094402313\n",
            "\n",
            "Epoch - 94 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.6141263246536255\n",
            "\n",
            "Epoch - 95 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 1.128055453300476\n",
            "\n",
            "Epoch - 96 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.7522510886192322\n",
            "\n",
            "Epoch - 97 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.5326399207115173\n",
            "\n",
            "Epoch - 98 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'at', 'a', 'ladder', 'painting', 'a', 'sign', '.', '<eos>']\n",
            "Epoch_Loss - 0.9472973346710205\n",
            "\n",
            "Epoch - 99 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.40044328570365906\n",
            "\n",
            "Epoch - 100 / 100\n",
            "Translated example sentence 1: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
            "Epoch_Loss - 0.2237810492515564\n",
            "\n",
            "92.26179225342769\n",
            "Bleu score 15.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqylUksMJtVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b85f51ef-9dc9-4524-b8c8-fa2758012bde"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "%tensorboard --logdir runs/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yyYsPQ2ml7Y",
        "colab_type": "text"
      },
      "source": [
        "# 11. Seq2Seq Model Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8seg8haidFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "progress  = []\n",
        "import nltk\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "for i, sen in enumerate(ts1):\n",
        "  progress.append(TreebankWordDetokenizer().detokenize(sen))\n",
        "print(progress)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH2U-LbhH1dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "progress_df = pd.DataFrame(data = progress, columns=['Predicted Sentence'])\n",
        "progress_df.index.name = \"Epochs\"\n",
        "progress_df.to_csv('/content/predicted_sentence.csv')\n",
        "progress_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAUieohaNpvd",
        "colab_type": "text"
      },
      "source": [
        "# Model Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxcYB6cRJKIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "test_sentences  = [\"Zwei Männer gehen die Straße entlang\", \"Kinder spielen im Park.\", \"Diese Stadt verdient eine bessere Klasse von Verbrechern. Der Spaßvogel\"]\n",
        "actual_sentences  = [\"Two men are walking down the street\", \"Children play in the park\", \"This city deserves a better class of criminals. The joker\"]\n",
        "pred_sentences = []\n",
        "\n",
        "for idx, i in enumerate(test_sentences):\n",
        "  model.eval()\n",
        "  translated_sentence = translate_sentence(model, i, german, english, device, max_length=50)\n",
        "  progress.append(TreebankWordDetokenizer().detokenize(translated_sentence))\n",
        "  print(\"German : {}\".format(i))\n",
        "  print(\"Actual Sentence in English : {}\".format(actual_sentences[idx]))\n",
        "  print(\"Predicted Sentence in English : {}\".format(progress[-1]))\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}